{
    "filename": "ML Task.pdf",
    "filepath": "C:\\Users\\lenova\\Desktop\\ChatBot\\ML Task.pdf",
    "content": "Hackathon Task: Document-based \nRAG Chatbot \nObjective \nBuild a chatbot capable of answering user queries based strictly on the content \nprovided in a set of PDF and Word documents. The system must be built using a \nRetrieval-Augmented Generation (RAG) architecture and adhere to all the conditions \nlisted below. \nScope of Work \nYou will be provided with a set of PDF and Word documents. Your task is to \nimplement a chatbot that uses these documents as its only source of information to \nanswer user queries. \nGeneral Conditions \n1. The total time to process and respond to a user query must not exceed 15 \nseconds. (Applicable only when you are running on GPU) \n2. LangChain or any component of LangChain is not allowed. \n3. Only open-source LLMs and embedding models are to be used. \n4. API calls to external models or services (e.g., OpenAI, Claude, Gemini, \nMistral API, etc.) are not allowed. \n5. The chatbot must accurately identify and display the exact document source \nused for each answer. (Must display document filename, page number, and \nexact chunk/section identifier used for the answer) \n6. The displayed document link must correspond only to the content used in \ngenerating the answer, not all retrieved chunks. (Answer Generator LLM must \ntake care of document link) \n7. You may use any open-source framework for chunking the documents. \n8. The chunking method you use must be justified with clear reasoning. \n9. Only one vector database query is allowed per user question.  (you can\u2019t \nquery the DB multiple times) \n10. You are allowed to use metadata-based filtering strategies if needed. \n11. Qdrant must be used as the vector database (Nothing else). \n12. The chatbot's answers must be directly extracted from the retrieved context. \n13. If the LLM cannot find the answer in the provided context, it should tell the \nsame to the user. \n14. The complete solution must be able to run on a Tesla T4 GPU. (Must include \nGPU/CPU memory usage analysis and optimization strategies. If Tesla T4 is \nnot available, provide detailed resource usage documentation showing \ncompatibility with 16GB GPU memory limit) \n15. You may use any platform to run your code (e.g., Kaggle, Google Colab, or \nyour local system). \n16. Create a UI using any of these (Streamlit / Gradio / Chainlit / Reflex) to solve \nthis problem. Except for the mentioned frameworks, do not use anything else \nto create a UI. \n17. Once completed, this entire solution should run on a local system without \ninternet. (Assuming all models, dependencies, and data must be downloaded \nand cached locally.) \nOptional Features (Not Mandatory) \n1. You are not required to support greeting or casual conversation inputs. \n2. You are not required to support follow-up or threaded questions. \n3. You are not required to create a good interactive UI for this. A basic UI which \ncan take user input text and return a response is enough. \nSubmission Requirements \n1. Submit your complete codebase in a GitHub repository with a README file \n(MUST be a formatted README). \n2. Content for README.md -> explaining setup, usage, and architectural \ndecisions, observations, chunking strategy, retrieval approach, and hardware \nusage. (Order does not matter) \n3. Submit a document which includes 10 (Must be 10) queries with response text \nand screenshot of the response in a FORMATTED document (PDF / Word / \ntxt \u2014 anything on any shareable platform).  \n4. If you fail at any point of this task, MUST explain in the README why you \nfailed, how long it would take to make this chatbot work, and how you would \nmake it work. \n5. You MUST submit a DEMO VIDEO LINK (YouTube, Google Drive, or any \nshareable platform) that satisfies all the following conditions:  \na. The video must show you (the presenter) on camera with your face \nclearly visible throughout the video. \nb. The video must include live testing of the chatbot on at least 5 \nquestions taken from the 10 questions you will submit in your response \ndocument. \nc. You are required to run the full application live during the recording. \nThis means run the chatbot application from scratch in front of the \ncamera. \nd. Input the questions manually and show the real-time responses. \ne. No part of the video should be cropped, cut, or edited. We want to see \nthe entire interaction and system behaviour in real time. Pre-recorded \ninteractions, UI mock-ups, or trimmed demos will lead to \ndisqualification. \nBonus Points (Only do this if you have time left) \n1. Create an architecture of this entire chatbot for production (Be creative). \n2. Tell us in which part of the code you used AI (ChatGPT, Claude, Cursor, \nWindsurf...) to write code and how you generally use these kinds of tools. \nEvaluation Criteria \nCriteria \nWeight \nAccuracy of Answers \n30% \nAccuracy of Source Document \nLink \n20% \nJustification of Chunking Method \n10% \nResponse Time Within Limit \n10% \nCode Quality and Modularity \n10% \nExtra Enhancements \n10% \nGood README file on GitHub \n10%"
}